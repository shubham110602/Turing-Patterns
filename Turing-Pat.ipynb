{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7832377,"sourceType":"datasetVersion","datasetId":4590437},{"sourceId":8015573,"sourceType":"datasetVersion","datasetId":4722475},{"sourceId":8018545,"sourceType":"datasetVersion","datasetId":4724635},{"sourceId":8079747,"sourceType":"datasetVersion","datasetId":4768676}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"import torch\nimport torchvision.models as models\nfrom torchvision import transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch import nn\nimport pandas as pd\nimport cv2\nimport imghdr\nfrom sklearn.metrics import classification_report\nfrom matplotlib import pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/turing-patterns/Monidipa_Shubham'):\n    for filename in filenames:\n        file_path = os.path.join(dirname, filename)\n        try:\n            img = cv2.imread(file_path)\n            tip = imghdr.what(file_path)\n#             print(tip)\n            if tip != 'png':\n                print('Image not in ext list {}'.format(file_path))\n                os.remove(file_path)\n        except Exception as e:\n            print('Issue with image {}'.format(file_path))\n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-15T11:32:26.647474Z","iopub.execute_input":"2024-04-15T11:32:26.648209Z","iopub.status.idle":"2024-04-15T11:32:27.266799Z","shell.execute_reply.started":"2024-04-15T11:32:26.648177Z","shell.execute_reply":"2024-04-15T11:32:27.266016Z"}}},{"cell_type":"code","source":"# CUDA_LAUNCH_BLOCKING=1\n# TORCH_USE_CUDA_DSA","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:27.268552Z","iopub.execute_input":"2024-04-15T11:32:27.269165Z","iopub.status.idle":"2024-04-15T11:32:27.273012Z","shell.execute_reply.started":"2024-04-15T11:32:27.269127Z","shell.execute_reply":"2024-04-15T11:32:27.272036Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/turing-patterns/Monidipa_Shubham'\nspiral_dir = '/kaggle/input/spirals'\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(3),  # Convert to RGB (3 channels)\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.5], std=[0.5]),\n])\n\ndataset = datasets.ImageFolder(root = data_dir, transform=transform)\nclass_names = dataset.classes\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:27.274048Z","iopub.execute_input":"2024-04-15T11:32:27.274310Z","iopub.status.idle":"2024-04-15T11:32:27.287038Z","shell.execute_reply.started":"2024-04-15T11:32:27.274287Z","shell.execute_reply":"2024-04-15T11:32:27.286174Z"},"trusted":true},"execution_count":161,"outputs":[{"name":"stdout","text":"['Spirals', 'Spots', 'Strips']\n","output_type":"stream"}]},{"cell_type":"code","source":"loader = DataLoader(dataset, batch_size=64, shuffle=True)\n\nmean_sum = torch.zeros(3)\nstd_sum = torch.zeros(3)\ncount = 0\n\n# Calculate mean and standard deviation for each channel\nfor images, _ in loader:\n    batch_size = images.size(0)\n    count += batch_size\n    mean_sum += images.mean(dim=[0, 2, 3]) * batch_size\n    std_sum += images.std(dim=[0, 2, 3]) * batch_size\n\n# Calculate the overall mean and standard deviation\nmean = mean_sum / count\nstd = std_sum / count\n\nprint(f\"Estimated Mean: {mean}\")\nprint(f\"Estimated Std: {std}\")\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:27.289432Z","iopub.execute_input":"2024-04-15T11:32:27.289854Z","iopub.status.idle":"2024-04-15T11:32:28.329460Z","shell.execute_reply.started":"2024-04-15T11:32:27.289821Z","shell.execute_reply":"2024-04-15T11:32:28.328482Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"Estimated Mean: tensor([0.7122, 0.7122, 0.7122])\nEstimated Std: tensor([0.2701, 0.2701, 0.2701])\n","output_type":"stream"}]},{"cell_type":"code","source":"normalize_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ndataset = datasets.ImageFolder(root=data_dir, transform=normalize_transform)\nspirals = datasets.ImageFolder(root=spiral_dir, transform=normalize_transform)\n# print(data.class_to_idx)\n# for image, labels in dataloader:\n#     print(labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:28.330693Z","iopub.execute_input":"2024-04-15T11:32:28.331044Z","iopub.status.idle":"2024-04-15T11:32:28.339844Z","shell.execute_reply.started":"2024-04-15T11:32:28.331011Z","shell.execute_reply":"2024-04-15T11:32:28.339004Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"train_size = int(len(dataset)*.7)\n# valid_size = int(len(dataset)*.2)\ntest_size = int(len(dataset) - train_size)\n\ntrain, test = random_split(dataset, [train_size, test_size])\n\nbatch_size = 32\ntrain_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n# valid_dataloader = DataLoader(valid, batch_size=batch_size, shuffle=False)\ntest_dataloader = DataLoader(test, batch_size=batch_size, shuffle=False)\n# spiral_dataloader = DataLoader(spirals, batch_size=batch_size, shuffle=False)\n# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.Grayscale(3),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.5], std=[0.5]),\n# ])\n\n# mnist_train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n# mnist_test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n\n# train_loader = DataLoader(mnist_train_dataset, batch_size=32, shuffle=True)\n# test_loader = DataLoader(mnist_test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:28.340915Z","iopub.execute_input":"2024-04-15T11:32:28.341166Z","iopub.status.idle":"2024-04-15T11:32:28.353105Z","shell.execute_reply.started":"2024-04-15T11:32:28.341144Z","shell.execute_reply":"2024-04-15T11:32:28.352171Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"# class CNNModel(nn.Module):\n#     def __init__(self, num_classes = 3):\n#         super(CNNModel, self).__init__()\n        \n#         self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1)\n#         self.bn1 = nn.BatchNorm2d(64)\n#         self.conv2 = nn.Conv2d(64, 128, kernel_size = 3, stride =1 )\n#         self.bn2 = nn.BatchNorm2d(128)\n#         self.conv3 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1)\n#         self.bn3 = nn.BatchNorm2d(256)\n        \n#         self.relu = nn.ReLU()\n#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n#         self.fc1 = nn.Linear(256*26*26, 512)\n#         self.bn4 = nn.BatchNorm1d(512)\n#         self.fc2 = nn.Linear(512, num_classes)\n#         self.bn5 = nn.BatchNorm1d(num_classes)\n        \n#         self.softmax = nn.Softmax(dim=1)\n    \n#     def forward(self, x):\n# #         print(x.size())\n#         x = self.pool(self.relu(self.bn1(self.conv1(x))))\n# #         print(x.size())\n#         x = self.pool(self.relu(self.bn2(self.conv2(x))))\n# #         print(x.size())\n#         x = self.pool(self.relu(self.bn3(self.conv3(x))))\n# #         print(x.size())\n#         x = x.view(-1, 256*26*26)\n#         print(x.size())\n#         x = self.relu(self.bn4(self.fc1(x)))\n#         print(x.size())\n#         x = self.bn5(self.fc2(x))\n#         x = F.log_softmax(x, 1)\n# #         print(x.size())\n        \n#         return x\n\n# model = CNNModel().to('cuda')\n# criterion = nn.CrossEntropyLoss()\n# optimiser = optim.Adam(model.parameters(), lr=0.001)\n\nalexnet_model = models.vgg16(pretrained=True)\n\nnum_features = alexnet_model.classifier[6].in_features\nalexnet_model.classifier[6] = nn.Linear(num_features, 3)\nalexnet_model = alexnet_model.to(\"cuda\")\nalexnet_model.train()\n\n# num_ftrs = alexnet_model.fc.in_features\n# alexnet_model.fc = torch.nn.Linear(num_ftrs, 3)\n# alexnet_model = alexnet_model.to(\"cuda\")\n# alexnet_model.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:28.354367Z","iopub.execute_input":"2024-04-15T11:32:28.355115Z","iopub.status.idle":"2024-04-15T11:32:30.135264Z","shell.execute_reply.started":"2024-04-15T11:32:28.355080Z","shell.execute_reply":"2024-04-15T11:32:30.134316Z"},"trusted":true},"execution_count":165,"outputs":[{"execution_count":165,"output_type":"execute_result","data":{"text/plain":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU(inplace=True)\n    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU(inplace=True)\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (6): ReLU(inplace=True)\n    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (8): ReLU(inplace=True)\n    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (13): ReLU(inplace=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (18): ReLU(inplace=True)\n    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (20): ReLU(inplace=True)\n    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (22): ReLU(inplace=True)\n    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): ReLU(inplace=True)\n    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (27): ReLU(inplace=True)\n    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (29): ReLU(inplace=True)\n    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=3, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimiser = optim.RMSprop(alexnet_model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:30.136392Z","iopub.execute_input":"2024-04-15T11:32:30.136673Z","iopub.status.idle":"2024-04-15T11:32:30.142181Z","shell.execute_reply.started":"2024-04-15T11:32:30.136650Z","shell.execute_reply":"2024-04-15T11:32:30.141172Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"num_epoch = 5\n# for epoch in range(num_epoch):\n#     alexnet_model.train()\n#     train_loss = 0.0\n#     for images, labels in train_dataloader:\n#         images, labels = images.to('cuda'), labels.to('cuda')\n#         optimiser.zero_grad()\n#         output = alexnet_model(images)\n# #         output = output.float()\n# #         labels = labels.long()\n# #         print(output)\n#         loss = criterion(output, labels)\n#         loss.backward()\n#         optimiser.step()\n#         total_loss = loss.item()\n        \n#     avg_loss = total_loss/len(train_dataloader)\n#     print(f'Training Epoch [{epoch+1}/{num_epoch}], Loss: {avg_loss}')\n    \n\n\nfor epoch in range(num_epoch):\n    for inputs, labels in train_dataloader:\n        optimiser.zero_grad()\n        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n        outputs = alexnet_model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimiser.step()\n        \n    print(f\"Epoch [{epoch+1}/{num_epoch}], Loss: {loss.item()}\")\n    \n# torch.save(model.state_dict(), 'custom_cnn_model_gpu.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:30.143759Z","iopub.execute_input":"2024-04-15T11:32:30.144079Z","iopub.status.idle":"2024-04-15T11:32:34.538402Z","shell.execute_reply.started":"2024-04-15T11:32:30.144049Z","shell.execute_reply":"2024-04-15T11:32:34.537450Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 10035682304.0\nEpoch [2/5], Loss: 6623.23095703125\nEpoch [3/5], Loss: 3207.948486328125\nEpoch [4/5], Loss: 98.7304458618164\nEpoch [5/5], Loss: 226.54747009277344\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For AlexNet\nEpoch [1/5], Loss: 0.0\nEpoch [2/5], Loss: 0.0\nEpoch [3/5], Loss: 0.0\nEpoch [4/5], Loss: 0.0\nEpoch [5/5], Loss: 0.0\n\nFor ResNet\nEpoch [1/5], Loss: 2.1291191577911377\nEpoch [2/5], Loss: 2.1237082481384277\nEpoch [3/5], Loss: 2.1333234310150146\nEpoch [4/5], Loss: 2.130035161972046\nEpoch [5/5], Loss: 2.127274751663208","metadata":{}},{"cell_type":"code","source":"alexnet_model.eval()\nfor epoch in range(num_epoch):\n    \n    correct = 0\n    total = 0\n    for images, labels in test_dataloader:\n#         print(images)\n#         fig, axes = plt.subplots(1,1)\n#         axes.imshow(images)\n#         plt.show()\n#         plt.imshow(images)\n#         t_i = normalize_transform(images)\n#         actual_batch_size = images.size(0)\n#         plt.figure(figsize=(15, 15))  # Adjust figure size as needed\n#         for i in range(actual_batch_size):\n#             plt.subplot(4, 8, i + 1)  # Assuming 32 images will be displayed in a 4x8 grid\n# #             plt.imshow(transforms.ToPILImage()(images[i]))\n#             plt.imshow((images[i].permute(1, 2, 0)))# Convert tensor back to PIL Image for plotting\n#             plt.title(f'Label: {class_names[labels[i]]}')\n#             plt.axis('off')\n#         plt.show()\n        images, labels = images.to('cuda'), labels.to('cuda')\n        \n        optimiser.zero_grad()\n        output = alexnet_model(images)\n        i, predicted = torch.max(output.data, 1)\n        \n#         print(labels)\n#         for i in range(actual_batch_size):\n#             print(class_names[predicted[i]])\n#         print(predicted)\n        correct += predicted.eq(labels).sum().item()\n        total += labels.size(0)\n    \n    accuracy = correct/total\n    print(f\"Epoch {epoch + 1}/{num_epoch}, Validation Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:34.541674Z","iopub.execute_input":"2024-04-15T11:32:34.541970Z","iopub.status.idle":"2024-04-15T11:32:36.267825Z","shell.execute_reply.started":"2024-04-15T11:32:34.541946Z","shell.execute_reply":"2024-04-15T11:32:36.266884Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stdout","text":"Epoch 1/5, Validation Accuracy: 66.67%\nEpoch 2/5, Validation Accuracy: 66.67%\nEpoch 3/5, Validation Accuracy: 66.67%\nEpoch 4/5, Validation Accuracy: 66.67%\nEpoch 5/5, Validation Accuracy: 66.67%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For AlexNet\nEpoch 1/5, Validation Accuracy: 100.00%\nEpoch 2/5, Validation Accuracy: 100.00%\nEpoch 3/5, Validation Accuracy: 100.00%\nEpoch 4/5, Validation Accuracy: 100.00%\nEpoch 5/5, Validation Accuracy: 100.00%\n\nFor ResNet\nEpoch 1/5, Validation Accuracy: 0.00%\nEpoch 2/5, Validation Accuracy: 0.00%\nEpoch 3/5, Validation Accuracy: 0.00%\nEpoch 4/5, Validation Accuracy: 0.00%\nEpoch 5/5, Validation Accuracy: 0.00%","metadata":{}},{"cell_type":"code","source":"# alexnet_model.eval()\n# for epoch in range(num_epoch):\n    \n#     correct = 0\n#     total = 0\n#     for images, labels in spiral_dataloader:\n# #         print(images)\n# #         fig, axes = plt.subplots(1,1)\n# #         axes.imshow(images)\n# #         plt.show()\n# #         plt.imshow(images)\n# #         t_i = normalize_transform(images)\n#         actual_batch_size = images.size(0)\n#         plt.figure(figsize=(15, 15))  # Adjust figure size as needed\n#         for i in range(actual_batch_size):\n#             plt.subplot(4, 8, i + 1)  # Assuming 32 images will be displayed in a 4x8 grid\n# #             plt.imshow(transforms.ToPILImage()(images[i]))\n#             plt.imshow((images[i].permute(1, 2, 0)))# Convert tensor back to PIL Image for plotting\n#             plt.title(f'Label: {class_names[labels[i]]}')\n#             plt.axis('off')\n#         plt.show()\n#         images, labels = images.to('cuda'), labels.to('cuda')\n        \n#         optimiser.zero_grad()\n#         output = alexnet_model(images)\n#         i, predicted = torch.max(output.data, 1)\n        \n# #         print(labels)\n#         for i in range(actual_batch_size):\n#             print(class_names[predicted[i]])\n# #         print(predicted)\n#         correct += predicted.eq(labels).sum().item()\n#         total += labels.size(0)\n    \n#     accuracy = correct/total\n#     print(f\"Epoch {epoch + 1}/{num_epoch}, Validation Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:36.269123Z","iopub.execute_input":"2024-04-15T11:32:36.269484Z","iopub.status.idle":"2024-04-15T11:32:36.275109Z","shell.execute_reply.started":"2024-04-15T11:32:36.269450Z","shell.execute_reply":"2024-04-15T11:32:36.274130Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"# alexnet_model.eval()\n# y_true=[]\n# y_pred=[]\n# with torch.no_grad():\n#     for test_data in test_dataloader:\n#         images, labels = images.to('cuda'), labels.to('cuda')\n#         pred = alexnet_model(images).argmax(dim=1)\n#         for i in range(len(pred)):\n#             y_true.append(labels[i].item())\n#             y_pred.append(pred[i].item())\n# print(len(y_true))\n# print(classification_report(y_true,y_pred,target_names=class_names,digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-04-15T11:32:36.276358Z","iopub.execute_input":"2024-04-15T11:32:36.276716Z","iopub.status.idle":"2024-04-15T11:32:36.290891Z","shell.execute_reply.started":"2024-04-15T11:32:36.276684Z","shell.execute_reply":"2024-04-15T11:32:36.290109Z"},"trusted":true},"execution_count":170,"outputs":[]}]}